{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis of multivariate random variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. You need to make a non-parametric estimation of PDF in form of histogram and using kernel density function for MRV (or probability law in case of discrete MRV)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(\n",
    "    df,\n",
    "    dimensions=df_ml,#[\"year_of_release\", \"na_sales\", \"eu_sales\", \"jp_sales\", \"other_sales\"],\n",
    "    color='genre'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Parametric estimation of PDF',\n",
    "    width=1000,\n",
    "    height=1000,\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ml = df.query('critic_score != \"unknown\"').copy()\n",
    "df_ml = df_ml.query('user_score != \"unknown\"')\n",
    "df_ml['critic_score'] = df_ml['critic_score'].astype('int')\n",
    "df_ml['user_score'] = df_ml['user_score'].astype('float')\n",
    "\n",
    "sns.set_theme(style='whitegrid', palette='pastel')\n",
    "\n",
    "ax = sns.pairplot(\n",
    "    df_ml,\n",
    "    diag_kind='kde'\n",
    ")\n",
    "ax.map_lower(sns.kdeplot, levels=6, color='.1')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', palette='pastel')\n",
    "\n",
    "ax = sns.pairplot(\n",
    "    df_ml,\n",
    "    kind=\"hist\",\n",
    "    diag_kind='hist'\n",
    ")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(\n",
    "    df,\n",
    "    x = 'year_of_release',\n",
    "    y = 'genre',\n",
    "    # z = 'passengers',\n",
    "    title = 'Non-parametric estimation of PDF', # Non-parametric estimation of PDF\n",
    "    #     color_continuous_scale = px.colors.diverging.BrBG, # not to be used with marginal_x and marginal_y\n",
    "    marginal_x = 'histogram',\n",
    "    marginal_y = 'histogram'\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2. You need to make an estimation of multivariate mathematical expectation and variance."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(df.describe().T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.var()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3. You need to make a non-parametric estimation of conditional distributions, mathematical expectations and variances."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(3, 2, figsize=(20, 15))\n",
    "sns.set_theme(style='whitegrid', palette='husl')\n",
    "\n",
    "year_of_release = sns.histplot(df.year_of_release, ax=ax[0, 0], kde=True, stat='density')\n",
    "year_of_release.set(xlabel='Year Of Release')\n",
    "\n",
    "na_sales = sns.histplot(df.na_sales, ax=ax[0, 1], kde=True, stat='density')\n",
    "na_sales.set(xlabel='na_sales')\n",
    "\n",
    "eu_sales = sns.histplot(df.eu_sales, ax=ax[1, 0], kde=True, stat='density')\n",
    "eu_sales.set(xlabel='eu_sales')\n",
    "\n",
    "jp_sales = sns.histplot(df.jp_sales, ax=ax[1, 1], kde=True, stat='density')\n",
    "jp_sales.set(xlabel='jp_sales')\n",
    "\n",
    "other_sales = sns.histplot(df.other_sales, ax=ax[2, 0], kde=True, stat='density')\n",
    "other_sales.set(xlabel='other_sales')\n",
    "\n",
    "world_sales = sns.histplot(df.world_sales, ax=ax[2, 1], kde=True, stat='density')\n",
    "world_sales.set(xlabel='world_sales')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "# np.random.seed(1)\n",
    "\n",
    "x = df.year_of_release\n",
    "hist_data = [df.year_of_release]\n",
    "group_labels = ['Year Of Release'] # name of the dataset\n",
    "\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x1 = df.na_sales\n",
    "x2 = df.eu_sales\n",
    "x3 = df.jp_sales\n",
    "x4 = df.other_sales\n",
    "x5 = df.world_sales\n",
    "\n",
    "hist_data = [x1, x2, x3, x4, x5]\n",
    "\n",
    "group_labels = ['na_sales', 'eu_sales', \"jp_sales\", 'other_sales', 'world_sales']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "fig = ff.create_distplot(hist_data, group_labels)\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_variables = [\n",
    "    'name', 'platform', 'year_of_release', 'genre',\n",
    "    'na_sales', 'eu_sales', 'jp_sales', 'other_sales', 'world_sales',\n",
    "    'critic_score', 'user_score', 'rating',\n",
    "]\n",
    "\n",
    "conditions = [2000, 2005, 2010, 2015]\n",
    "\n",
    "\n",
    "conditional_mean = pd.DataFrame([], index=all_variables)\n",
    "conditional_var = pd.DataFrame([], index=all_variables)\n",
    "\n",
    "for condition in conditions:\n",
    "    tmp_df = df_ml[df_ml[\"year_of_release\"] == condition][all_variables]\n",
    "    conditional_mean[f\"year_of_release = {condition}\"] = tmp_df.mean(axis=0)\n",
    "    conditional_var[f\"year_of_release = {condition}\"] = tmp_df.var(axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conditional_mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conditional_var"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4. You need to make an estimation of pair correlation coefficients, confidence intervals for them and significance levels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(df[['na_sales', 'jp_sales', 'eu_sales']].corr(), cmap='Blues', annot=True, linewidths=0.25)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.imshow(\n",
    "    df[['na_sales', 'jp_sales', 'eu_sales']].corr(),\n",
    "    text_auto=True,\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Thus, sales in North America have a high correlation with sales in Japan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "def estimate(values, target):\n",
    "    r, pvalue = scipy.stats.pearsonr(values, target)\n",
    "\n",
    "    conf_int = st.t.interval(0.95, len(values)-1, loc=np.mean(values), scale=st.sem(values))\n",
    "\n",
    "    print(f'Correlation Coefficient: {r} \\nSignificance Level: {pvalue}\\nConfidence Interval: {conf_int}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe_data = ohe.fit_transform(df[['genre']])\n",
    "ohe_data.toarray()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimate(df.jp_sales, df.na_sales)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5. Choose a task formulation for regression. Estimate multivariate correlation (target - predictors)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.get_dummies(df['genre'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df.info()\n",
    "data = df.query('critic_score != \"unknown\" & rating == [\"E\", \"T\", \"M\"]')\n",
    "data['critic_score'] = data['critic_score'].map(float) # astype(float)\n",
    "# data['critic_score'].value_counts()\n",
    "data['rating'].value_counts()\n",
    "# data.info()\n",
    "data = data[['critic_score', 'rating', 'genre', 'na_sales']]\n",
    "# df['genre'] = pd.get_dummies(df['genre'])\n",
    "data = pd.get_dummies(data, columns=['genre', 'rating'])\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6. Build regression model and make an analysis of multicollinearity and regularization (if needed)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split data\n",
    "df_X = data.drop(columns='critic_score')\n",
    "df_y = data['na_sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Teach regressor\n",
    "cls_lr = LinearRegression()\n",
    "cls_lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = cls_lr.predict(X_test)\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Lasso regularization\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.coef_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(X_train, y_train)\n",
    "alpha_aic_ = model_aic.coef_\n",
    "alpha_aic_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_lasso = clf.predict(X_test)\n",
    "y_pred_lasso_aic = model_aic.predict(X_test)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "mae_lasso_aic = mean_absolute_error(y_test, y_pred_lasso_aic)\n",
    "print('Mean absolute error with lasso = ', mae_lasso)\n",
    "print('Mean squared error with lasso = ', mse_lasso)\n",
    "print('Mean absolute error with aic lasso = ', mae_lasso_aic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 7. Analyze the quality of regression model (distribution of residuals, determination coefficient)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mae(y_test, y_pred):\n",
    "    print(f\"MAE {mean_absolute_error(y_test, y_pred)}\\n\")\n",
    "\n",
    "\n",
    "def mape(y_test, y_pred):\n",
    "    print(f\"MAPE {mean_absolute_percentage_error(y_test, y_pred)}\\n\")\n",
    "\n",
    "def mse(y_test, y_pred):\n",
    "    print(f\"MSE {mean_squared_error(y_test, y_pred)}\\n\")\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    # squaredbool, default=True\n",
    "    # If True returns MSE value, if False returns RMSE value.\n",
    "    print(f\"RMSE {mean_squared_error(y_test, y_pred, squared=False)}\\n\")\n",
    "\n",
    "def residuals_dist(y_test, y_pred):\n",
    "\n",
    "    data = y_test - y_pred\n",
    "\n",
    "    figure, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "    residuals = sns.histplot(data, ax=ax, kde=True, stat='density')\n",
    "    residuals.set(xlabel='Distribution of Residuals')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_regression_metrics(y_test, y_pred):\n",
    "    mae(y_test, y_pred)\n",
    "    mape(y_test, y_pred)\n",
    "    mse(y_test, y_pred)\n",
    "    rmse(y_test, y_pred)\n",
    "    residuals_dist(y_test, y_pred)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print('r2 score ', r2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_regression_metrics(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Confidence interval of regression coef\n",
    "import numpy as np, statsmodels.api as sm\n",
    "mod = sm.OLS(y_train, X_train)\n",
    "res = mod.fit()\n",
    "print(res.conf_int(0.01))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
